{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 1 - Sentiment Analysis on Tweeter with key word(Trump)\n",
    "## By Alan Tan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the outputs in a cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Create 4 different lists: tweet, positive, negative, stopwords\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List 1 - Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"b'trump\",\n",
       " 'germans',\n",
       " 'could',\n",
       " 'be',\n",
       " '\\\\xe2\\\\x80\\\\x9cleft',\n",
       " 'without',\n",
       " 'a',\n",
       " 'country\\\\xe2\\\\x80\\\\x9d\\\\xc2\\\\xa0soon',\n",
       " \"https//tco/2pt6yaopmz\\\\n'b'robreiner\",\n",
       " 'after',\n",
       " 'watching',\n",
       " 'trump\\\\xe2\\\\x80\\\\x99s',\n",
       " 'rally',\n",
       " 'in',\n",
       " 'ohio',\n",
       " 'there',\n",
       " 'is',\n",
       " 'no',\n",
       " 'other',\n",
       " 'way']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "51720"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "f = open('Trump_Raw_Tweets.txt', 'r')\n",
    "for w in f:\n",
    "    w = w.lower()\n",
    "    w = w.strip()\n",
    "    w = w.replace('@','').replace(':','').replace('.', '').\\\n",
    "        replace(',','').replace('rt ','').replace('?','')\n",
    "\n",
    "    for w in w.split():\n",
    "        tweets.append(w)\n",
    "tweets[:20]\n",
    "len(tweets)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List 2 - Positive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2006"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['a+',\n",
       " 'abound',\n",
       " 'abounds',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'accessable',\n",
       " 'accessible',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'acclamation',\n",
       " 'accolade',\n",
       " 'accolades',\n",
       " 'accommodative',\n",
       " 'accomodative',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accurate',\n",
       " 'accurately']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = []\n",
    "f = open('positive.txt', 'r')\n",
    "for w in f:\n",
    "    w = w.lower()\n",
    "    w = w.strip()\n",
    "    positive.append(w)\n",
    "len(positive)\n",
    "positive[:20]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List 3 - Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4783"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['2-faced',\n",
       " '2-faces',\n",
       " 'abnormal',\n",
       " 'abolish',\n",
       " 'abominable',\n",
       " 'abominably',\n",
       " 'abominate',\n",
       " 'abomination',\n",
       " 'abort',\n",
       " 'aborted',\n",
       " 'aborts',\n",
       " 'abrade',\n",
       " 'abrasive',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abscond',\n",
       " 'absence',\n",
       " 'absent-minded',\n",
       " 'absentee',\n",
       " 'absurd']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative = []\n",
    "f = open('negative.txt', 'r')\n",
    "for w in f:\n",
    "    w = w.lower()\n",
    "    w = w.strip()\n",
    "    negative.append(w)\n",
    "len(negative)\n",
    "negative[:20]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List 4 - Stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amoungst']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword = []\n",
    "f = open('stopwords.txt', 'r')\n",
    "for w in f:\n",
    "    w = w.lower()\n",
    "    w = w.strip()\n",
    "    stopword.append(w)\n",
    "len(stopword)\n",
    "stopword[:20]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the words in tweets with list - positive, negative and stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_s = 0\n",
    "count_n = 0\n",
    "count_p = 0\n",
    "count_o = 0\n",
    "count_all = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive word count = 2697 \n",
      "negative word count = 2063 \n",
      "stopword word count = 20650 \n",
      "others word count = 26310 \n",
      "all word count = 51720 \n",
      "===================================\n",
      "positive ratio = 0.05 \n",
      "negative ratio = 0.04 \n",
      "stop ratio = 0.40 \n",
      "others ratio = 0.51 \n",
      "positive vs negative ratio = 1.31 \n",
      "CPU times: user 3.04 s, sys: 16.2 ms, total: 3.06 s\n",
      "Wall time: 3.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for w in tweets:\n",
    "    count_all +=1\n",
    "    if w in positive:\n",
    "        count_p += 1\n",
    "    elif w in negative:\n",
    "        count_n += 1\n",
    "    elif w in stopword:\n",
    "        count_s += 1\n",
    "    else:\n",
    "        count_o += 1\n",
    "\n",
    "print (\"positive word count = %d \" % count_p)\n",
    "print (\"negative word count = %d \" % count_n)\n",
    "print (\"stopword word count = %d \" % count_s)\n",
    "print (\"others word count = %d \" % count_o)\n",
    "print (\"all word count = %d \" % count_all)\n",
    "\n",
    "\n",
    "print (\"===================================\")\n",
    "print ('positive ratio = %.2f ' % (count_p/count_all) )\n",
    "print ('negative ratio = %.2f ' % (count_n/count_all) )\n",
    "print ('stop ratio = %.2f ' % (count_s/count_all) )\n",
    "print ('others ratio = %.2f ' % (count_o/count_all) )\n",
    "\n",
    "print ('positive vs negative ratio = %.2f ' % (count_p/count_n) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same routine but now we convert the *list* into a *set*. The look up in *set*  is much faster than *list*. Observe the execution time difference(in almost the same code as above but with 3 sets instead of 3 lists). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_set=set(positive)\n",
    "negative_set=set(negative)\n",
    "stopword_set=set(stopword)\n",
    "type(positive_set)\n",
    "type(negative_set)\n",
    "type(stopword_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_s = 0\n",
    "count_n = 0\n",
    "count_p = 0\n",
    "count_o = 0\n",
    "count_all = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive word count = 2697 \n",
      "negative word count = 2063 \n",
      "stopword word count = 20650 \n",
      "others word count = 26310 \n",
      "all word count = 51720 \n",
      "===================================\n",
      "positive ratio = 0.05 \n",
      "negative ratio = 0.04 \n",
      "stop ratio = 0.40 \n",
      "others ratio = 0.51 \n",
      "positive vs negative ratio = 1.31 \n",
      "CPU times: user 18.1 ms, sys: 2.42 ms, total: 20.5 ms\n",
      "Wall time: 18.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for w in tweets:\n",
    "    count_all +=1\n",
    "    if w in positive_set:\n",
    "        count_p += 1\n",
    "    elif w in negative_set:\n",
    "        count_n += 1\n",
    "    elif w in stopword_set:\n",
    "        count_s += 1\n",
    "    else:\n",
    "        count_o += 1\n",
    "\n",
    "print (\"positive word count = %d \" % count_p)\n",
    "print (\"negative word count = %d \" % count_n)\n",
    "print (\"stopword word count = %d \" % count_s)\n",
    "print (\"others word count = %d \" % count_o)\n",
    "print (\"all word count = %d \" % count_all)\n",
    "\n",
    "\n",
    "print (\"===================================\")\n",
    "print ('positive ratio = %.2f ' % (count_p/count_all) )\n",
    "print ('negative ratio = %.2f ' % (count_n/count_all) )\n",
    "print ('stop ratio = %.2f ' % (count_s/count_all) )\n",
    "print ('others ratio = %.2f ' % (count_o/count_all) )\n",
    "\n",
    "print ('positive vs negative ratio = %.2f ' % (count_p/count_n) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe the difference in above execution speeds between list and set\n",
    "#### In instructor's Macbook Pro laptop, the 'set' data type is ~160 times faster than 'list' data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Conclusion: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERY Positive trend of keyword 'Trump'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Or is it really correct ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'trump' in positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 'trump' is a positive word !!! which will bias our analysis a lot !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 'trump' word count = 1647\n",
      "The corrected positive word count reduced from 2697 to 1050\n",
      "=========================================\n",
      "negative word count = 2063\n",
      "positive word count(corrected) = 1050\n",
      "positive ratio = 0.02 \n",
      "negative ratio = 0.04 \n",
      "corrected positive vs negative ratio  = 0.51\n"
     ]
    }
   ],
   "source": [
    "count_trump = 0\n",
    "count_p_corrected = 0\n",
    "\n",
    "for w in tweets:\n",
    "    if (w in positive) & (w == 'trump'):\n",
    "        count_trump += 1\n",
    "print ('word \\'trump\\' word count = %d' % count_trump)\n",
    "\n",
    "count_p_corrected = count_p - count_trump\n",
    "print ('The corrected positive word count reduced from %d to %d' % \\\n",
    "       (count_p, count_p_corrected) )\n",
    "print ('=========================================')\n",
    "print ('negative word count = %d' % count_n)\n",
    "print ('positive word count(corrected) = %d' % count_p_corrected)\n",
    "print ('positive ratio = %.2f ' % (count_p_corrected/count_all) )\n",
    "print ('negative ratio = %.2f ' % (count_n/count_all) )\n",
    "print ('corrected positive vs negative ratio  = %.2f' % \\\n",
    "       (count_p_corrected/count_n) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct Conclusion:\n",
    "* Very Negative sentiment in Trump related tweets !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More checking - duplication in positive/negative/stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word in both neg and stop - cry \n",
      "word in both pos and stop - enough \n",
      "word in both pos and stop - sincere \n",
      "word in both pos and stop - top \n",
      "word in both pos and stop - well \n"
     ]
    }
   ],
   "source": [
    "for w in stopword:\n",
    "    if w in positive:\n",
    "        print('word in both pos and stop - %s ' % str(w) )\n",
    "    elif w in negative:\n",
    "        print('word in both neg and stop - %s ' % str(w) )    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word in both pos and neg - envious \n",
      "word in both pos and neg - enviously \n",
      "word in both pos and neg - enviousness \n"
     ]
    }
   ],
   "source": [
    "for w in positive:\n",
    "    if w in negative:\n",
    "        print('word in both pos and neg - %s ' % str(w) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It will be your call to do further actions while counting the positive/negative/stopwords or just treat them as \"noise\" if your data sample is large enough. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Extra Note: How to perform further clean up (<b>NOT</b> for execution) \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "with open(\"Trump_Raw_Tweets.txt\",\"r\") as txt:\n",
    "    lines=txt.read()\n",
    "\n",
    "# Cleaning the tweets data for url strings\n",
    "lines = re.sub('https://[a-zA-Z0-9./]*',' ',lines)\n",
    "\n",
    "# Cleaning the tweets data for different usernames\n",
    "lines=re.sub('@[a-zA-Z0-9_:]*','',lines)\n",
    "\n",
    "#Cleaning the tweets data for smiley emojis\n",
    "lines=re.sub('\\\\\\\\x[a-zA-Z0-9]*','',lines)\n",
    "\n",
    "#Cleaning the tweets data for new line, special characters and retweet notations\n",
    "lines=re.sub('(\\\\\\\\n)|(b[\"\\'](RT)?)|[/?>.<_+=|,\"\\':;{}\\[\\])(*^%$#@!~`\\\\\\\\-]', ' ', lines)\n",
    "\n",
    "#Cleaning the tweets data for extra spaces and replacing with single space\n",
    "lines=re.sub(' +',' ',lines)\n",
    "\n",
    "#Removing beginning and trailing spaces using strip function and converting to list of \n",
    "#strings using split function\n",
    "Trump_tweets=lines.strip().lower().split(\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
